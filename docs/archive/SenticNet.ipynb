{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SenticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`````{admonition} SenticNet summary \n",
    ":class: tip\n",
    "\n",
    "**Overview:** SenticNet is a conceptual lexicon providing multidimensional sentiment ratings for commonsense concepts and expressions. \n",
    "\n",
    "**Composition:** \n",
    "- 300,000 concepts (n-grams) \n",
    "- Provides both categorical emotion labels (moods and semantics) and multidimensional activation levels across `Introspection`, `Temper` `Attitude` and `Sensitivity`\n",
    "\n",
    "**Creation Methodology:**  \n",
    "- Knowledge sourced from commonsense databases like ConceptNet, WordNet-Affect then enriched via graph mining techniques and multi-dimensional scaling in the AffectiveSpace model\n",
    "- Annotates concepts with granular labels from Hourglass of Emotions framework - each of the 24 emotions has 6 sentic levels capturing intensity  \n",
    "- Developed over 7 iterations since 2010, consistently improving methodology. Earlier versions relied on graph mining and dimensionality reduction. More recent versions incorporate neural symbolic AI to expand conceptual coverage and enhance representation\n",
    "\n",
    "**Evaluation:** SenticNet has been validated primarily using cross-dictionary comparisons. \n",
    "\n",
    "For SenticNet 1 (Cambria et al., 2010), polarity detection accuracy was tested on a dataset of 2,000 patient opinions labelled as 57% negative and 32% positive. Concepts were extracted from the opinions and matched to polarity scores in SenticNet and SentiWordNet. SenticNet showed much higher precision (79% vs 53%) and recall (58% vs 46%) for identifying positive opinions, with an overall F-measure of 67% compared to SentiWordNet's 49%.\n",
    "\n",
    "For SenticNet 7 (Cambria et al., 2022), performance was compared against 20 popular sentiment dictionaries on 10 benchmark datasets including SST (Socher et al., 2016) and Semeval sentiment analysis task series (Nakov et al., 2019; Rosenthal et al., 2015). The analysis framed sentiment detection as binary classification, ignoring neutral labels. When possible, each dictionary used its own detection framework. With 300,000 entries including n-grams, SenticNet 7 achieved the best accuracy out of all dictionaries - ranging from 77.04% to 90.08%. \n",
    "\n",
    "**Usage Guidance:** A rich conceptual lexicon for more semantic-oriented sentiment analysis. Provides multidimensional ratings to model affective dynamics. Useful for nuanced emotion detection. Access via `sentibank.archive.load().dict(\"SenticNet_v{year}\")` with available versions from 2010-2022.\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{contents}\n",
    ":local:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Introduction \n",
    "\n",
    "SenticNet was initially designed to address gaps in SentiWordNet's coverage of common sense concepts frequently used to convey sentiment (Cambria et al., 2010). For instance, SentiWordNet lacked polarity ratings for concepts like ‚Äúaccomplish goal‚Äù and ‚Äúbe on cloud nine‚Äù. Over seven iterations, SenticNet has leveraged different state-of-the-art methods at that particular period of time to expand its conceptual lexicon (Cambria et al., 2010; Cambria, Havasi and Hussain, 2012; Cambria, Olsher and Rajagopal, 2014; Cambria et al., 2016; Cambria et al., 2018; Cambria et al., 2020; Cambria et al., 2022). With each new version, SenticNet incorporated the latest techniques available to grow its coverage and enhance its representational capacity. \n",
    "\n",
    "But the consistent motivation of SenticNet has been to move beyond the classic bag-of-words model to a richer bag-of-concepts model that associates polarity with more complex multiword expressions. While the bag-of-words approach relies on the frequencies of individual words, the bag-of-concepts representation aligns more closely with human understanding by capturing semantic relationships between words and the sentiments evoked by common concepts. This allows SenticNet to provide a more meaningful basis for opinion mining compared to syntax-based approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Original Dictionary \n",
    "\n",
    "The SenticNet lexicon has steadily expanded over multiple versions, each leveraging state-of-the-art techniques to encode sentiment for an increasing breadth of commonsense concepts. \n",
    "\n",
    "SenticNet 1 (Cambria et al., 2010) assigned polarity scores to ~6,000 ConceptNet concepts using affective commonsense knowledge from sources like ConceptNet, WordNet-Affect, and the Hourglass of Emotions model. SenticNet 2 (Cambria, Havasi and Hussain, 2012) built on this by adding semantic labels for ~14,000 entries. SenticNet 3 (Cambria, Olsher and Rajagopal, 2014) then deviated in its approach - rather than graph mining, it represented concepts by modelling the flow of information between semantic fragments. This modular emotional modelling expanded the coverage to ~30,000 concepts. \n",
    "\n",
    "SenticNet 4 (Cambria et al., 2016) introduced semantic primitives, applying techniques like hierarchical clustering to generalise ~50,000 concepts. SenticNet 5 (Cambria et al., 2018) coupled symbolic and subsymbolic neural networks to infer primitives via lexical substitution, reaching ~100,000 entries with a three-tier knowledge representation. SenticNet 6 (Cambria et al., 2020) further combined symbolic and subsymbolic methods (i.e BiLSTM and BERT) to provide sentiment scores for ~200,000 commonsense concepts. Finally, SenticNet 7 (Cambria et al., 2022) brings this knowledge resource up to 300,000 concepts using neurosymbolic AI for explainable sentiment analysis.\n",
    "\n",
    "While SenticNet has evolved over seven versions, its emotion labelling has consistently built upon two key frameworks: AffectiveSpace and the Hourglass of Emotions. Across all versions, including the latest releases (Cambria et al., 2020, 2022), concepts are mapped to these models to assign multidimensional sentiment scores. \n",
    "\n",
    "### AffectiveSpace \n",
    "\n",
    "AffectiveSpace (Cambria et al., 2009) is a vector space of common sense concepts and emotions, in which different vectors represent different ways of making distinctions among concepts and emotions (Cambria et al., 2010). Put simply, concepts conveying the same emotion tend to fall near each other in AffectiveSpace. AffectiveSpace was built on top of commonsense knowledge sources like ConceptNet (Havasi, Speer and Alonso, 2007) and WordNet-Affect (Strapparava and Valitutti, 2004). \n",
    "\n",
    "### Hourglass of Emotions \n",
    "\n",
    "The Hourglass of Emotions is an affective categorization model originally developed by Plutchik (2001). It represents emotions along four key dimensions: `Pleasantness`, `Attention`, `Sensitivity`, and `Aptitude`. Different combinations and levels of ‚Äòactivation‚Äô along these dimensions characterise distinct emotional states. Rather than classifying emotions into basic categories, Hourglass of Emotions captured the concurrent, independent nature of emotional dimensions. \n",
    "\n",
    "This framework was revisited by Susanto et al. (2020) to address limitations in Plutchik's original formulation (pp.97-100). The dimensions were redefined as `Introspection`, `Temper`, `Attitude`, and `Sensitivity`. Additionally, the concept polarity formula was revised to be more proportional to the number of active dimensions. This better accounts for the complexity of bi-dimensional emotions like \"love\" (joy+pleasantness), tri-dimensional states like \"bittersweetness\" (sadness+anger+pleasantness), and rare four-dimensional emotions like \"jealousy\" (anger+fear+sadness+disgust) (Susanto et al., 2020; Consoli, Barbaglia and Manzan, 2022).  \n",
    "\n",
    "### Integration \n",
    "\n",
    "A key advantage of the Hourglass model is its ability to deconstruct emotions into independent yet interrelated dimensions. This modular approach allows concurrent consideration of multiple factors in generating nuanced affective states, supporting both categorical and dimensional views. SenticNet heavily exploited the semantic connections in AffectiveSpace to enrich links between concepts representing Hourglass activation levels (Cambria et al., 2010; Cambria, Olsher and Rajagopal, 2014).\n",
    "\n",
    "The emotion representation in SenticNet is defined by the 24 basic emotions within the Hourglass of Emotions (see Figure 1, Susanto et al., 2020, p.98). This model captures four affective dimensions, each with six levels of activation indicating emotion intensity. The cartesian product of these dimensions and activation levels gives the full set of 24 categories used to label SenticNet terms with rich sentiment signals. The integration of the two frameworks allows SenticNet to break down emotions into granular dimensions while harnessing related semantic knowledge from AffectiveSpace. This provides a flexible representation that encodes the complex affective dynamics of commonsense concepts through *both categorical emotion labels and multi-dimensional activation levels*.\n",
    "\n",
    "For example, out of the 24 emotions, ‚Äúclean‚Äù would be tagged with the `introspection` label based on its proximity to related concepts like ‚Äúcleaned‚Äù and ‚Äúimmaculate‚Äù in the AffectiveSpace model. Each dimension has 6 activation levels indicating emotion intensity, so \"clean\" may have a sentic level of `contentment`, reflecting a moderate sense of positive emotion. In this way, the 24 Hourglass labels with associated sentic levels allow SenticNet to specify intensity for the full spectrum of elementary emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentibank import archive\n",
    "\n",
    "load = archive.load()\n",
    "SenticNet = load.origin(\"SenticNet_v2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "timeout": 300
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from itables import init_notebook_mode, show \n",
    "init_notebook_mode(all_interactive=True)\n",
    "show(df=SenticNet, caption=\"SenticNet (Cambria et al., 2010; Cambria, Havasi and Hussain, 2012; Cambria, Olsher and Rajagopal, 2014; Cambria et al., 2016; Cambria et al., 2018; Cambria et al., 2020; Cambria et al., 2022)\", maxBytes=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Processed Dictionary \n",
    "### First-Pass Processing \n",
    "\n",
    "A key aspect of SenticNet is providing *both categorical emotion labels and multidimensional activation levels* to flexibly represent sentiment for concepts. As a result, multiple dictionary versions are available each year:  \n",
    "\n",
    "- `SenticNet_v{year}`: Includes sentiment scores between [-1, 1] indicating polarity intensity. Available for all versions.\n",
    "- `SenticNet_v{year}_semantics`: Labels concepts with categorical labels (e.g. \"a1\" -> [\"finest\", \"prime\", \"superior\"]). Added from v2010 onwards.  \n",
    "- `SenticNet_v{year}_attributes`: Vector representation of concepts across 4 key attributes - `Pleasantness`, `Attention`, `Sensitivity`, and `Aptitude`. From v2020, the dimensions were updated to `Introspection`, `Temper`, `Attitude`, and `Sensitivity`. Available from v2010 onwards.\n",
    "- `SenticNet_v{year}_mood`: Mood tags indicating emotions associated with concepts. Added from v2016 onwards. v2016-v2020 includes 8 general moods<sup>[2]</sup>, while v2022 expanded this to 24 emotions<sup>[3]</sup> from the Hourglass of Emotions.\n",
    "\n",
    "The only preprocessing change was to replace underscores with spaces for multiword expressions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note \n",
    "\n",
    "\n",
    "<sup>[1]</sup> Hourglass of Emotions classification with five sample emotion words for each category (Susanto et al., 2020, p.99, Table 2)\n",
    "\n",
    "INTROSPECTION\n",
    "\n",
    "| ECSTASY     | JOY         | CONTENTMENT | MELANCHOLY  | SADNESS     | GRIEF                 |\n",
    "|-------------|-------------|-------------|-------------|-------------|-----------------------|\n",
    "| elation     | happiness   | satisfaction| pensiveness | unhappiness | desperation           |\n",
    "| jubilation  | cheerfulness| gratification| abandonment | sorrow      | gloom                 |\n",
    "| exultation  | joviality   | fulfilment  | emptiness   | dejection   | depression            |\n",
    "| glee        | gaiety      | light-heartedness | down-heartedness | heavy-heartedness | broken-heartedness |\n",
    "| felicity    | high-spiritedness | frivolity | nostalgia  | low-spiritedness | woe                 |\n",
    "\n",
    "\n",
    "TEMPER\n",
    "\n",
    "| BLISS       | CALMNESS    | SERENITY    | ANNOYANCE   | ANGER       | RAGE                  |\n",
    "|-------------|-------------|-------------|-------------|-------------|-----------------------|\n",
    "| placidity   | tranquillity | quietude    | disquietude | vexation    | fury                  |\n",
    "| peacefulness| equanimity  | comfort     | discomfort  | exasperation| wrath                 |\n",
    "| beatitude   | composure   | ease        | unease      | aggressiveness| ferocity             |\n",
    "| gladness    | restfulness | imperturbability | perturbability | madness | enragement          |\n",
    "| relief      | soothingness| carefreeness | frustration | acrimoniousness| vengeance          |\n",
    "\n",
    "\n",
    "ATTITUDE\n",
    "\n",
    "| DELIGHT     | PLEASANTNESS| ACCEPTANCE  | DISLIKE     | DISGUST     | LOATHING              |\n",
    "|-------------|-------------|-------------|-------------|-------------|-----------------------|\n",
    "| admiration  | appreciation| approval    | disapproval | disappointment| contempt             |\n",
    "| adoration   | fondness    | favorability| distaste    | detestation | revulsion            |\n",
    "| glorification| predilection| propensity  | rejection   | disdain     | scorn                |\n",
    "| devotion   | respect     | belief      | disbelief   | disrespect  | repugnance           |\n",
    "| enthrallment| trust       | worthiness  | worthlessness| distrust   | abhorrence           |\n",
    "\n",
    "\n",
    "SENSITIVITY\n",
    "\n",
    "| ENTHUSIASM  | EAGERNESS   | RESPONSIVENESS | ANXIETY    | FEAR        | TERROR                |\n",
    "|-------------|-------------|-----------------|------------|-------------|-----------------------|\n",
    "| zeal        | keenness    | decisiveness   | indecisiveness| fright    | horror                |\n",
    "| zest        | willingness | receptiveness  | apprehension| dread      | panic                 |\n",
    "| passion     | motivation | agreeableness  | helplessness| trepidation | appalment           |\n",
    "| avidity     | inspiration | approachableness| agitation  | angst      | petrification         |\n",
    "| fervor      | dedication | amenability   | discouragement| scare     | aghastness            |\n",
    "\n",
    "<sup>[2]</sup> The 8 general moods are {'joy', 'surprise', 'admiration', 'disgust', 'interest', 'fear', 'sadness', 'anger'}. \n",
    "\n",
    "<sup>[3]</sup> The 24 (Hourglass) emotions are {'eagerness', 'pleasantness', 'calmness', 'serenity', 'contentment', 'fear', 'melancholy', 'grief', 'bliss', 'disgust', 'terror', 'dislike', 'sadness', 'annoyance', 'responsiveness', 'loathing', 'delight', 'anxiety', 'enthusiasm', 'anger', 'joy', 'rage', 'ecstasy', 'acceptance'}. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
