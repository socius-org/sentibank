{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MASTER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment expressions common in **financial regulatory filings ðŸ’¼, such as 10-K**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`````{admonition} Summary \n",
    ":class: tip\n",
    "\n",
    "**Composition:**\n",
    "- Approximately 3.8k unigram lexicon entries\n",
    "- Financial domain-specific business phrases and jargon\n",
    "- Multi-Class Multi-Label (`Negative`, `Positive`, `Uncertainty`, `Litigious`, `Strong_Modal`, `Weak_Modal`, and `Constraining`)\n",
    "\n",
    "**Creation Methodology:**\n",
    "- Lexicon candidates were based on tokens that appeared at least 5% of sampled 10-K filings\n",
    "- The tokens were then manually labelled by the authors \n",
    "\n",
    "**Evaluation:** Loughran and McDonald (2011) tested the significance of the MASTER dictionary by examining the marketâ€™s reaction at the time of a 10-K filing - â€˜*If tone matters, firms filing 10-Ks with a high measure of negative words should, on average, experience negative excess returns around the filing date*â€™ (p.18). Compared to the Harvard_GIâ€™s TagNeg Dictionary (H4N) which showed no significant association to the file date excess returns (t = -1.35, below 95% confidence), MASTERâ€™s â€˜Negativeâ€™ dictionary showed a statistically significant negative correlation (t = -2.64, above 99% confidence). \n",
    "\n",
    "Bodnaruk, Loughran and McDonald (2015) investigated how well â€˜*different measures are able to predict future developments associated with the deterioration or improvement of external financing conditions*â€™ (p.16). Compared to other â€˜traditional measures of financial constraintsâ€™, MASTERâ€™s â€˜Constrainingâ€™ dictionary was the only measure that predicted all four directions of ex-post liquidity events with 1% significance level (p.17, 40). \n",
    "\n",
    "**Usage Guidance:** Useful for analysis of finance publications, earnings calls, annual reports. Access processed dictionary via `sentibank.archive.load().dict(â€œMASTER_v2022â€)`. \n",
    "``````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{contents}\n",
    ":local:\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Introduction \n",
    "\n",
    "While a sentiment dictionary designed to be applied in the general domain may be useful, â€˜English words have many meanings, and a word categorisation scheme derived for one discipline might not translate effectively into a discipline with its own dialectâ€™ (Loughran and McDonald, 2011, p.1). Such generality could potentially lead to Type-I errors due to sentiment misclassification in a different context. For example, Loughran and McDonald (2011) revealed that nearly 73.8% of the negative word counts in Harvard Psychosociological TagNeg Dictionary (H4N) are actually words that are not typically negative in a financial context. \n",
    "\n",
    "To address such constraints, Loughran and McDonald (2011) created a finance-specific dictionary called [MASTER](https://sraf.nd.edu/loughranmcdonald-master-dictionary/). The dictionary is regularly updated by the authors, and was last updated in 2022."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Original Dictionary "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The master dictionary originally started with 6 labels â€“ `Negative`, `Positive`, `Uncertainty`, `Litigious`, `Strong_Modal`, and `Weak_Modal` â€“ but was later enhanced by Bodnaruk, Loughran and McDonald (2015) with addition of `Constraining` label. Note that both `Litigious` and `Constraining` lexicons capture a similar â€œtoneâ€: According to Bodnaruk, Loughran and McDonald (2015), there was a positive correlation between the frequency of `Constraining` lexicons and the frequency of `Litigious` lexicons in the 10-K samples. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ver.2011"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment lexicons of MASTER dictionary (ver.2011) is from a â€˜relatively exhaustive listâ€™ of tokens that occurred in at least 5% of 10-K documents between 1994-2008 (p.12). From the SECâ€™s [EDGAR](https://www.sec.gov/edgar/search-and-access), Loughran and McDonald (2011) collected 121,217 firm-year 10-K/10-K405 samples, which was later filtered into 50,115 samples consisting of 8,341 unique firms. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Filter                                                                                       | Sample Size | Dropped |\n",
    "|----------------------------------------------------------------------------------------------|-------------|---------------------|\n",
    "| EDGAR 10-K / 10-K405 1994-2008 complete sample (excluding duplicates)                        | 121,217     |                     |\n",
    "| Include only first filing in a given year                                                    | 120,290     | 927                 |\n",
    "| At least 180 days between a given firmâ€™s 10-K filings                                        | 120,074     | 216                 |\n",
    "| CRSP PERMNO match                                                                            | 75,252      | 44,822              |\n",
    "| Reported on CRSP as an ordinary common equity firm                                           | 70,061      | 5,191               |\n",
    "| CRSP market capitalization data available                                                   | 64,227      | 5,834               |\n",
    "| Price on filing date day minus one > $3                                                     | 55,946      | 8,281               |\n",
    "| Returns and volume for day 0-3 event period                                                  | 55,630      | 316                 |\n",
    "| NYSE, AMEX, or Nasdaq exchange listing                                                       | 55,612      | 18                  |\n",
    "| At least 60 days of returns and volume in year prior to and following file date               | 55,038      | 574                 |\n",
    "| Book-to-market COMPUSTAT data available and book value > 0                                   | 50,268      | 4,770               |\n",
    "| Number of words in 10-K > 2,000                                                              | 50,115      | 153                 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection of lexicons was further extended by accounting for its inflection (i.e for a token â€˜accidentâ€™, its inflections â€˜accidentalâ€™, â€˜accidentallyâ€™ and â€˜accidentsâ€™ were added) using ver.4.0 of 2of12inf dictionary developed by [SCOWL](http://wordlist.aspell.net/) <sup>[1],[2]</sup>. Note that Loughran and McDonald (2011) used inflections instead of stemming because â€˜*if the focus is on tone, using explicit inflections is less error prone than extending a word using stemming (root morpheme + derivational morphemes)*â€™ (Software Repository of Accounting and Finance, n.d.).  \n",
    "\n",
    "3,752 lexicons were collected, and Loughran and McDonald (2011) labelled such lexicons under 6 categories: `Negative`, `Positive`, `Uncertainty`, `Litigious`, `Strong_Modal` and `Weak_Modal`. There were 2,337 `Negative` lexicons (i.e â€˜felonyâ€™, â€˜litigationâ€™, â€˜restatedâ€™, â€˜misstatementâ€™, â€˜unanticipatedâ€™), while there were 353 `Positive` lexicons (i.e â€˜achieveâ€™, â€˜attainâ€™, â€˜efficientâ€™, â€˜improveâ€™, â€˜profitableâ€™), which were substantially fewer. The top 5 most frequently occurring `Negative` lexicons in the 10-Ks sample were â€˜lossâ€™, â€˜lossesâ€™, â€˜impairmentâ€™, â€˜againstâ€™ and â€˜adverseâ€™. \n",
    "\n",
    "There were 285 lexicons categorised as `Uncertainty` (i.e. 'approximate', 'contingency', 'depend', 'fluctuate', 'indefinite', 'uncertain', and 'variability'), emphasising the general notion of imprecision rather than exclusively focusing on risk. Additionally, there were 731 lexicons categorised as `Litigious` (i.e. 'claimant', 'deposition', 'interlocutory', 'testimony', and 'tort'), reflecting a propensity for legal contest. The inclusion of words like 'legislation' and 'regulation' was made, which do not necessarily imply a legal contest but may indicate a more litigious environment. It's important to note that many lexicons overlapped between the `Negative`, `Uncertainty`, and `Litigious` categories.\n",
    "\n",
    "Loughran and McDonald (2011) expanded Jordan's (1999, cited in Loughran and McDonald, 2011, p.14) categories of strong and weak modal words to include other terms expressing levels of confidence. There were 19 lexicons categorised as `Strong_Modal` (i.e. 'always', 'highest', 'must', and 'will'), and 27 lexicons categorised as `Weak_Modal` (i.e. 'could', 'depending', 'might', and 'possibly')."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ver.2015"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of the ver.2011 of master dictionary, Bodnaruk, Loughran and McDonald (2015) collected 184 lexicons that captures whether or not a firm is financially constrained (`Constraining`). Similar to Loughran and McDonald (2011), the collection was from tokens that appeared at least 5% of 10-K filings between 1996-2011. The original collection had 183,214 firm-year samples, which was filtered and reduced to 51,533. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Filter                                     | Sample Size | Dropped     |\n",
    "|-------------------------------------------|-------------|-------------|\n",
    "| SEC 10-K files 1996â€“2011                  | 183,214     |             |\n",
    "| Drop financial firms and utilities        | 133,992     | 49,222      |\n",
    "| Eliminate duplicates within year/CIK      | 130,450     | 3,542       |\n",
    "| Drop if file date < 180 days from prior   | 129,986     | 464         |\n",
    "| CRSP PERMNO match and ordinary common equity | 59,177   | 70,809      |\n",
    "| Drop if number of 10-K words is < 2,000   | 59,137      | 40          |\n",
    "| Drop if required Compustat data is missing | 55,530      | 3,607       |\n",
    "| Market capitalization data available on CRSP | 51,533    | 3,997       |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only seven lexicons,  â€˜requiredâ€™, â€˜obligationsâ€™, â€˜requirementsâ€™, â€˜requireâ€™, â€˜impairmentâ€™, â€˜obligationâ€™, and â€˜requiresâ€™, account for more than half of all the counts for the constraining words which appeared in 10-Ks. Appendix C (p.32) contains the entire list of `Constraining` lexicons, and Table 3 (p.39) reports the 50 most frequently occurring `Constraining` lexicons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ver.2022"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Master dictionary in SentiBank is the most up-to-date dictionary (ver.2022) maintained by Loughran and McDonald. While pre-2018 versions did not  include abbreviations in general, post-2018 versions are included with a limited number of abbreviations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentibank import archive\n",
    "\n",
    "load = archive.load()\n",
    "master = load.origin(\"MASTER_v2022\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoning</th>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandonment</th>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandonments</th>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrongdoing</th>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrongdoings</th>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrongful</th>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrongfully</th>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrongly</th>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3876 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sentiment\n",
       "abandon       [Negative]\n",
       "abandoned     [Negative]\n",
       "abandoning    [Negative]\n",
       "abandonment   [Negative]\n",
       "abandonments  [Negative]\n",
       "...                  ...\n",
       "wrongdoing    [Negative]\n",
       "wrongdoings   [Negative]\n",
       "wrongful      [Negative]\n",
       "wrongfully    [Negative]\n",
       "wrongly       [Negative]\n",
       "\n",
       "[3876 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itables import init_notebook_mode, show \n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n",
    "show(df=master, caption=\"MASTER (Loughran and McDonald, 2011; Bodnaruk, Loughran and McDonald, 2015)\", maxBytes=0) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Processed Dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the original csv, 8 select columns irrelevant to sentiment were programmatically filtered to purify the data for core sentiment modelling<sup>[3]</sup>. Upon filtration, the rows lacking substantive sentiment content were additionally removed to refine the dataset. As a result, the corpus of 86,531 were distilled into a lexicon of 3,876 domain-specific affect terms. No notable modifications or removals have been made further on the lexicons. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<sup>[1]</sup> To make sure all possible inflections are considered, Loughran and McDonald (2011) extended the core 2of12inf word list in the following procedure: (i) All tokens in variety of 10-K filings (10-K, 10-K/A, 10-K405, 10-K405/A, 10KSB, 10KSB/A, 10-KSB, 10-KSB/A, 10KSB40, 10KSB40/A) that did not appear in the 2of2inf word list were identified; (ii) Such a collection was then sorted by frequency of occurrence; and (iii) If a token had a frequency count of 50 or more OR was an inflection of a more common word, such a token was evaluated for inclusion in the master dictionary. \n",
    "\n",
    "<sup>[2]</sup> The 2of12inf dictionary originated from the [12dicts project](http://wordlist.aspell.net/12dicts-readme/), which explored different methods to extract core vocabulary lists from the 12 source dictionaries. From the name 2of12inf, the â€˜2of12â€™ represents the core vocabulary list containing over 40,000 words that appeared in at least 2 of the 12 source dictionaries. This excluded capitalised words, phrases, abbreviations, affixes, and non-American/secondary spellings.\n",
    "\n",
    "The â€˜infâ€™ represents the added inflections of those words, expanding the total size to around 81,000 words. However, 2of12inf diverged from only using the 12 source dictionaries. The starting point was a subset of the [AGID list](http://wordlist.aspell.net/agid-readme/) by Kevin Atkinson, incorporating public domain sources like [Moby Words](https://web.archive.org/web/20170930060409/http://icon.shef.ac.uk/Moby/) and [WordNet](https://wordnet.princeton.edu/). The list does not exclude secondary spellings, non-American usages\n",
    "\n",
    "In summary, 2of12inf ultimately optimised coverage at the cost of authority by inflecting 2of12 and adding public domain words. \n",
    "\n",
    "<sup>[3]</sup> The removed columns were `Seq_num`, `Word Count`, `Word Proportion`, `Average Proportion`, `Std Dev`, `Doc Count`, `Syllables`, `Source`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
